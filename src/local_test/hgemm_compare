#include <mma.h>
#include <vector>
#include <cstdio>
#include <iostream>
#include <cassert>
#include <functional>
#include <cuda_runtime.h> 
#include <algorithm>
#include <cublas_v2.h>
#include <cmath>

using namespace nvcuda;


#define K_UNROLL 8

#define DOUBLE_BUFFER_LEVEL 4
#define PAD(X,Y) (X % Y ? (X/Y+1)*Y : X)
#define BLOCK_DIM_DEFAULT 512
#define WARP_SIZE 32
#define TIMES 1


template <typename TIN,typename TOUT,int M_TILE,int N_TILE,int K_TILE>
__global__ void wmma_kernel(TIN * __restrict__ a, TIN * __restrict__ b, TOUT * __restrict__ c,int M_PAD,int N_PAD,int K_PAD) {
   int idx,midx,nidx,ndim,kdim;
   ndim = N_PAD / N_TILE;
   kdim = K_PAD / K_TILE;
   idx = (blockIdx.x*blockDim.x+threadIdx.x)/WARP_SIZE;

   if (idx >= (M_PAD/M_TILE) * (N_PAD/N_TILE)) {
       return;
   }
   nidx = idx%ndim;
   midx = idx/ndim;

   wmma::fragment<wmma::matrix_a, M_TILE, N_TILE, K_TILE, TIN, wmma::row_major> a_frag[DOUBLE_BUFFER_LEVEL];
   wmma::fragment<wmma::matrix_b, M_TILE, N_TILE, K_TILE, TIN, wmma::row_major> b_frag[DOUBLE_BUFFER_LEVEL];
   wmma::fragment<wmma::accumulator, M_TILE, N_TILE, K_TILE, TOUT> c_frag;

   wmma::fill_fragment(c_frag, 0.0f);

   // 增加边界检查，防止越界访问
   if (midx * M_TILE >= M_PAD || nidx * N_TILE >= N_PAD) {
       return;
   }
   TOUT * __restrict__ c_unique = c + nidx*N_TILE + midx*M_TILE*ndim*N_TILE;

   int kidx = 0;
   // 初始化双缓冲数据
   for (int i = 0; i < DOUBLE_BUFFER_LEVEL; ++i) {
       if (kidx + i >= kdim) break;
       TIN *a_unique = a + (kidx + i)*K_TILE + midx*M_TILE*kdim*K_TILE;
       TIN *b_unique = b + nidx*N_TILE + (kidx + i)*K_TILE*ndim*N_TILE;
       // 增加边界检查，防止越界访问
       if (midx * M_TILE >= M_PAD || (kidx + i) * K_TILE >= K_PAD) continue;
       if (nidx * N_TILE >= N_PAD || (kidx + i) * K_TILE >= K_PAD) continue;
       wmma::load_matrix_sync(a_frag[i], a_unique, K_PAD);
       wmma::load_matrix_sync(b_frag[i], b_unique, N_PAD);
   }
   kidx += DOUBLE_BUFFER_LEVEL;

   int read_idx = 0;
   int write_idx = (read_idx + 1) % DOUBLE_BUFFER_LEVEL;

   // 循环展开优化，减少循环开销
   // 使用双缓冲技术，提前加载下一轮数据，实现计算与数据加载的重叠
   for(; kidx + K_UNROLL - DOUBLE_BUFFER_LEVEL <= kdim; kidx += K_UNROLL - DOUBLE_BUFFER_LEVEL){
      // 计算当前轮数据
      for (int i = 0; i < K_UNROLL - DOUBLE_BUFFER_LEVEL; ++i) {
          if (kidx + i >= kdim) break;
          wmma::mma_sync(c_frag, a_frag[read_idx], b_frag[read_idx], c_frag);
          read_idx = (read_idx + 1) % DOUBLE_BUFFER_LEVEL;

          // 预加载下一轮数据
          if (kidx + i + DOUBLE_BUFFER_LEVEL - 1 >= kdim) break;
          TIN *a_unique = a + (kidx + i + DOUBLE_BUFFER_LEVEL - 1)*K_TILE + midx*M_TILE*kdim*K_TILE;
          TIN *b_unique = b + nidx*N_TILE + (kidx + i + DOUBLE_BUFFER_LEVEL - 1)*K_TILE*ndim*N_TILE;
          // 增加边界检查，防止越界访问
          if (midx * M_TILE >= M_PAD || (kidx + i + DOUBLE_BUFFER_LEVEL - 1) * K_TILE >= K_PAD) continue;
          if (nidx * N_TILE >= N_PAD || (kidx + i + DOUBLE_BUFFER_LEVEL - 1) * K_TILE >= K_PAD) continue;
          wmma::load_matrix_sync(a_frag[write_idx], a_unique, K_PAD);
          wmma::load_matrix_sync(b_frag[write_idx], b_unique, N_PAD);
          write_idx = (write_idx + 1) % DOUBLE_BUFFER_LEVEL;
      }
   }

   // 处理剩余的双缓冲数据
   for (int i = 0; i < DOUBLE_BUFFER_LEVEL; ++i) {
       if (kidx < kdim) {
           wmma::mma_sync(c_frag, a_frag[read_idx], b_frag[read_idx], c_frag);
           read_idx = (read_idx + 1) % DOUBLE_BUFFER_LEVEL;
           kidx++;
       }
   }

   // 处理剩余的循环
   for(; kidx < kdim; kidx++){
      TIN *a_unique = a + kidx*K_TILE + midx*M_TILE*kdim*K_TILE;
      TIN *b_unique = b + nidx*N_TILE + kidx*K_TILE*ndim*N_TILE;
      // 增加边界检查，防止越界访问
      if (midx * M_TILE >= M_PAD || kidx * K_TILE >= K_PAD) continue;
      if (nidx * N_TILE >= N_PAD || kidx * K_TILE >= K_PAD) continue;

      wmma::load_matrix_sync(a_frag[0], a_unique, K_PAD);
      wmma::load_matrix_sync(b_frag[0], b_unique, N_PAD);

      wmma::mma_sync(c_frag, a_frag[0], b_frag[0], c_frag);
   }
   // 增加边界检查，防止越界访问
   if (midx * M_TILE >= M_PAD || nidx * N_TILE >= N_PAD) {
       return;
   }
   wmma::store_matrix_sync(c_unique, c_frag, N_PAD, wmma::mem_row_major);
}

template <typename T> struct cuda_data {
  T *data;
  cuda_data(size_t n) {
    cudaMallocManaged(&data, sizeof(T) * n);
    // 检查内存分配是否成功
    if (data == nullptr) {
        std::cerr << "Failed to allocate CUDA memory!" << std::endl;
        exit(EXIT_FAILURE);
    }
    for(long i=0;i<n;i++){
      data[i] = 0;
    }
  }
  ~cuda_data() {
    cudaFree(data);
  }
};

enum DIR {ARR2CUARR,CUARR2ARR};

template <typename TARR,typename TCUARR,DIR dir>
void copy(int ARR_M,int ARR_N,TARR *arr,
      int CUARR_M,int CUARR_N,cuda_data<TCUARR> &cuarr){
   assert(CUARR_M>=ARR_M && CUARR_N>=ARR_N);
   if(dir==ARR2CUARR){
      for(int i=0;i<ARR_M;i++)
      for(int j=0;j<ARR_N;j++){
         cuarr.data[i*CUARR_N+j] = arr[i*ARR_N+j];
      }
   }else if(dir==CUARR2ARR){
      for(int i=0;i<ARR_M;i++){
         for(int j=0;j<ARR_N;j++){
            arr[i*ARR_N+j] = cuarr.data[i*CUARR_N+j];
         }
      }
   }else assert(0);
}

// 修改 Timer 函数，使其返回最小时间
float Timer(const char *tag, const std::function<void()> &kernel,int test_time = TIMES) {
  float min_time = 9e99;
  for (int i = 0; i < test_time; ++i) {
    cudaEvent_t beg, end;
    cudaEventCreate(&beg);
    cudaEventCreate(&end);

    if (beg == nullptr || end == nullptr) {
        std::cerr << "Failed to create CUDA event!" << std::endl;
        continue;
    }
    cudaDeviceSynchronize();
    cudaEventRecord(beg);
    kernel();

    cudaDeviceSynchronize();
    cudaEventRecord(end);
    cudaEventSynchronize(end);
    float elapsed_time;
    cudaEventElapsedTime(&elapsed_time, beg, end);
    min_time = std::min(min_time, elapsed_time);
    std::printf("[%s] iter %d: %f ms elapsed, %f ms min.\n", tag, i,elapsed_time, min_time);

    cudaEventDestroy(beg);
    cudaEventDestroy(end);
  }
  return min_time;
}

float compute_rel_error(const std::vector<float>& wmma_result, const std::vector<float>& cublas_result) {
    float diff_sum = 0.0f;
    float ref_sum = 0.0f;
    for (size_t i = 0; i < wmma_result.size(); ++i) {
        diff_sum += std::abs(wmma_result[i] - cublas_result[i]);
        ref_sum += std::abs(cublas_result[i]);
    }
    return diff_sum / ref_sum;
}

void cublas_gemm(int M, int N, int K, const float* A, const float* B, float* C) {
    cublasHandle_t handle;
    cublasStatus_t status = cublasCreate(&handle);
    if (status != CUBLAS_STATUS_SUCCESS) {
        std::cerr << "Failed to create cuBLAS handle!" << std::endl;
        return;
    }

    float *d_A, *d_B, *d_C;
    cudaMalloc(&d_A, M * K * sizeof(float));
    cudaMalloc(&d_B, K * N * sizeof(float));
    cudaMalloc(&d_C, M * N * sizeof(float));

    if (d_A == nullptr || d_B == nullptr || d_C == nullptr) {
        std::cerr << "Failed to allocate CUDA memory in cuBLAS!" << std::endl;
        cublasDestroy(handle);
        return;
    }

    cudaMemcpy(d_A, A, M * K * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, B, K * N * sizeof(float), cudaMemcpyHostToDevice);

    const float alpha = 1.0f;
    const float beta = 0.0f;

    cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, 
                N, M, K, 
                &alpha, 
                d_B, N, 
                d_A, K, 
                &beta, 
                d_C, N);

    cudaMemcpy(C, d_C, M * N * sizeof(float), cudaMemcpyDeviceToHost);

    cudaFree(d_A);
    cudaFree(d_B);
    cudaFree(d_C);
    cublasDestroy(handle);
}

template <typename TIN, typename TOUT,typename TGEMMIN=half, typename TGEMMOUT=float,int M_TILE=16,int N_TILE=16,int K_TILE=16>
void GEMM_wmma(int M,int N,int K,TIN *a_in,TIN *b_in,TOUT *c_out){
   assert(M!=0 && N!=0 && K!=0);

   const int M_PAD = PAD(M,M_TILE) ;
   const int N_PAD = PAD(N,N_TILE) ;
   const int K_PAD = PAD(K,K_TILE) ;

   cuda_data<TGEMMIN> a(M_PAD*K_PAD),b(K_PAD*N_PAD);
   cuda_data<TGEMMOUT> c(M_PAD*N_PAD);

   copy<TIN,TGEMMIN,ARR2CUARR>(M,K,a_in,M_PAD,K_PAD,a);
   copy<TIN,TGEMMIN,ARR2CUARR>(K,N,b_in,K_PAD,N_PAD,b);

   int GRID_DIM,BLOCK_DIM,nwarp;
   nwarp = (M_PAD/M_TILE) * (N_PAD/N_TILE);
   if(nwarp*WARP_SIZE < BLOCK_DIM_DEFAULT){
      GRID_DIM = 1;
      BLOCK_DIM = nwarp*WARP_SIZE;
   }else{
      GRID_DIM = (nwarp*WARP_SIZE)%BLOCK_DIM_DEFAULT ? nwarp*WARP_SIZE/BLOCK_DIM_DEFAULT+1 : nwarp*WARP_SIZE/BLOCK_DIM_DEFAULT ;
      BLOCK_DIM = BLOCK_DIM_DEFAULT;
   }
   printf("GRID_DIM:%d BLOCK_DIM:%d\n",GRID_DIM,BLOCK_DIM);

   wmma_kernel<TGEMMIN,TGEMMOUT,M_TILE,N_TILE,K_TILE>
      <<<GRID_DIM,BLOCK_DIM>>>(a.data,b.data,c.data,
            M_PAD,N_PAD,K_PAD);
   cudaDeviceSynchronize();

   cudaDeviceSynchronize();
   copy<TOUT,TGEMMOUT,CUARR2ARR>(M,N,c_out,M_PAD,N_PAD,c);
}

int main(int argc, char** argv) {

    struct TestCase {
        const char* name;
        int M;
        int N;
        int K;
    };


    TestCase test_cases[] = {
        {"Case1", 768, 768, 768},
        {"Case2", 128, 1024, 2048},
        {"Case3", 128, 2048, 8192},
        {"Case4", 512, 3072, 1024},
        {"Case5", 512, 4096, 8192},
        {"Case6", 3136, 576, 64},
        {"Case7", 4096, 4096, 4096},
        {"Case8", 1024, 16384, 16384},
        {"Case9", 4096, 16384, 14336},
        {"Case10", 32768, 32768, 32768}
    };

    // 遍历所有测试样例
    for (const auto& test_case : test_cases) {
        std::cout << "\n=== Testing " << test_case.name << " (M=" << test_case.M 
                  << ", N=" << test_case.N << ", K=" << test_case.K << ") ===\n";

        std::vector<float> h_a(test_case.M * test_case.K);
        std::vector<float> h_b(test_case.K * test_case.N);
        std::vector<float> h_c_wmma(test_case.M * test_case.N);
        std::vector<float> h_c_cublas(test_case.M * test_case.N);

        for (int i = 0; i < test_case.M * test_case.K; ++i) {
            h_a[i] = static_cast<float>(i % 10); 
        }
        for (int i = 0; i < test_case.K * test_case.N; ++i) {
            h_b[i] = static_cast<float>(i % 5); 
        }

        // 在计时前进行一次额外的 kernel 启动，预热 GPU
        GEMM_wmma<float, float>(test_case.M, test_case.N, test_case.K, h_a.data(), h_b.data(), h_c_wmma.data());
        cudaDeviceSynchronize();

        // 计时 WMMA 计算
        // 避免在计时函数中重复创建和销毁设备内存，将数据准备和传输移出计时范围
        cuda_data<half> a(test_case.M * test_case.K);
        cuda_data<half> b(test_case.K * test_case.N);
        cuda_data<float> c(test_case.M * test_case.N);
        copy<float, half, ARR2CUARR>(test_case.M, test_case.K, h_a.data(), test_case.M, test_case.K, a);
        copy<float, half, ARR2CUARR>(test_case.K, test_case.N, h_b.data(), test_case.K, test_case.N, b);

        float wmma_time = Timer("WMMA", [&]{
            const int M_PAD = PAD(test_case.M, 16);
            const int N_PAD = PAD(test_case.N, 16);
            const int K_PAD = PAD(test_case.K, 16);
            int GRID_DIM, BLOCK_DIM, nwarp;
            nwarp = (M_PAD / 16) * (N_PAD / 16);
            if (nwarp * WARP_SIZE < BLOCK_DIM_DEFAULT) {
                GRID_DIM = 1;
                BLOCK_DIM = nwarp * WARP_SIZE;
            } else {
                GRID_DIM = (nwarp * WARP_SIZE) % BLOCK_DIM_DEFAULT ? nwarp * WARP_SIZE / BLOCK_DIM_DEFAULT + 1 : nwarp * WARP_SIZE / BLOCK_DIM_DEFAULT;
                BLOCK_DIM = BLOCK_DIM_DEFAULT;
            }
            wmma_kernel<half, float, 16, 16, 16>
                <<<GRID_DIM, BLOCK_DIM>>>(a.data, b.data, c.data, M_PAD, N_PAD, K_PAD);
            cudaDeviceSynchronize();
        });
        copy<float, float, CUARR2ARR>(test_case.M, test_case.N, h_c_wmma.data(), test_case.M, test_case.N, c);

        // 在计时前进行一次额外的 cuBLAS 调用，预热 GPU
        cublas_gemm(test_case.M, test_case.N, test_case.K, h_a.data(), h_b.data(), h_c_cublas.data());
        cudaDeviceSynchronize();

        // 计时 cuBLAS 计算
        float cublas_time = Timer("cuBLAS", [&]{
            cublas_gemm(test_case.M, test_case.N, test_case.K, h_a.data(), h_b.data(), h_c_cublas.data());
        });

        float rel_error = compute_rel_error(h_c_wmma, h_c_cublas);
        std::cout << "Relative error between WMMA and cuBLAS results: " << rel_error << std::endl;

        if (rel_error < 0.05f) {
            std::cout << "Validation PASSED (rel_error < 0.05)" << std::endl;
        } else {
            std::cout << "Validation FAILED (rel_error >= 0.05)" << std::endl;
        }

        std::cout << "Performance comparison:" << std::endl;
        std::cout << "WMMA min time: " << wmma_time << " ms" << std::endl;
        std::cout << "cuBLAS min time: " << cublas_time << " ms" << std::endl;
        if (wmma_time < cublas_time) {
            std::cout << "WMMA is " << cublas_time / wmma_time << "x faster than cuBLAS." << std::endl;
        } else {
            std::cout << "cuBLAS is " << wmma_time / cublas_time << "x faster than WMMA." << std::endl;
        }
    }

    return 0;
}

//ssh -p 18188 sustcsc_11@172.18.6.40
